import cv2
import mediapipe as mp
import numpy as np

# ===== ì´ˆê¸° ì„¤ì •: ì† ì¸ì‹ + ì–¼êµ´ ì¸ì‹ =====
mp_hands = mp.solutions.hands
mp_face = mp.solutions.face_detection 
hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7)
face_detection = mp_face.FaceDetection(model_selection=0, min_detection_confidence=0.5)

# ğŸ¥ ì¹´ë©”ë¼ ì´ˆê¸°í™” (ì˜¤ë¥˜ ì²˜ë¦¬ ì¶”ê°€)
cap = cv2.VideoCapture(0)
if not cap.isOpened():
    print("âŒ ì˜¤ë¥˜: ì¹´ë©”ë¼ë¥¼ ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
    print("âœ… í•´ê²° ë°©ë²•:")
    print("   1. USB ì¹´ë©”ë¼ê°€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
    print("   2. ë‹¤ë¥¸ ì•±ì—ì„œ ì¹´ë©”ë¼ë¥¼ ì‚¬ìš© ì¤‘ì´ë©´ ì¢…ë£Œí•˜ì„¸ìš”")
    print("   3. ì‹œìŠ¤í…œ ì„¤ì • > ë³´ì•ˆ > ì¹´ë©”ë¼ ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”")
    exit()

# ğŸ“ 3D íë¸Œ ë°ì´í„°
points = np.array([
    [-1, -1, 1], [1, -1, 1], [1, 1, 1], [-1, 1, 1],
    [-1, -1, -1], [1, -1, -1], [1, 1, -1], [-1, 1, -1]
], dtype=float)
edges = [(0,1), (1,2), (2,3), (3,0), (4,5), (5,6), (6,7), (7,4), (0,4), (1,5), (2,6), (3,7)]

# íšŒì „ ê°ë„ ë° ì† ì œì–´ ë³€ìˆ˜
angle_x, angle_y = 0, 0
prev_pos = None

# âš™ï¸ ì‚¬ìš©ì ì¡°ì • ê°€ëŠ¥í•œ ì„¤ì •
PINCH_THRESHOLD = 0.05  # í•€ì¹˜ ê°ë„ (ì‘ì„ìˆ˜ë¡ ë¯¼ê°í•¨, 0.03~0.1 ì¶”ì²œ)
BLUR_STRENGTH = 55       # ë¸”ëŸ¬ ê°•ë„ (í™€ìˆ˜ë§Œ ê°€ëŠ¥: 21, 35, 55 ë“±)
SENSITIVITY = 0.01       # íšŒì „ ê°ë„ (ì‘ì„ìˆ˜ë¡ ëŠë¦¼)

while cap.isOpened():
    success, image = cap.read()
    if not success: 
        print("âš ï¸ ê²½ê³ : ì¹´ë©”ë¼ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        break

    image = cv2.flip(image, 1)
    h, w, _ = image.shape
    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # ===== ì–¼êµ´ ë¸”ëŸ¬ ì²˜ë¦¬ =====
    face_results = face_detection.process(rgb_image)
    if face_results.detections:
        for detection in face_results.detections:
            bbox = detection.location_data.relative_bounding_box
            x, y, fw, fh = int(bbox.xmin * w), int(bbox.ymin * h), int(bbox.width * w), int(bbox.height * h)
            
            # ğŸ‘ï¸ ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ (ë²”ìœ„ ê²€ì¦ ì¶”ê°€)
            y_start = max(0, y)
            y_end = min(h, y + fh)
            x_start = max(0, x)
            x_end = min(w, x + fw)
            
            face_roi = image[y_start:y_end, x_start:x_end]
            if face_roi.size > 0:
                # ë¸”ëŸ¬ ê°•ë„ ì¡°ì ˆ (BLUR_STRENGTH ìˆ«ìë¥¼ í‚¤ìš°ë©´ ë” ë¿Œì˜ˆì§‘ë‹ˆë‹¤)
                blurred_face = cv2.GaussianBlur(face_roi, (BLUR_STRENGTH, BLUR_STRENGTH), 0)
                image[y_start:y_end, x_start:x_end] = blurred_face

    # ===== ì† ì¸ì‹ ë° íë¸Œ ì œì–´ =====
    hand_results = hands.process(rgb_image)
    if hand_results.multi_hand_landmarks:
        for hand_landmarks in hand_results.multi_hand_landmarks:
            t = hand_landmarks.landmark[4]  # ì—„ì§€
            i = hand_landmarks.landmark[8]  # ê²€ì§€
            
            # ì†ê°€ë½ ê±°ë¦¬ ê³„ì‚° (ê°’ ê²€ì¦ ì¶”ê°€)
            dist = np.linalg.norm(np.array([t.x - i.x, t.y - i.y]))
            curr_pos = np.array([t.x * w, t.y * h])

            # ğŸ¯ í•€ì¹˜ ì œìŠ¤ì²˜ ê°ì§€ (PINCH_THRESHOLDë¡œ ì¡°ì ˆ ê°€ëŠ¥)
            if dist < PINCH_THRESHOLD:
                if prev_pos is not None:
                    dx = curr_pos[0] - prev_pos[0]
                    dy = curr_pos[1] - prev_pos[1]
                    angle_y += dx * SENSITIVITY
                    angle_x -= dy * SENSITIVITY  # ìƒí•˜ ì“¸ì–´ì˜¬ë¦¬ê¸°ë¡œ ì¡°ì ˆ
                prev_pos = curr_pos
                cv2.circle(image, (int(curr_pos[0]), int(curr_pos[1])), 10, (0, 255, 0), -1)
            else:
                prev_pos = None

    # ===== 3D íšŒì „ í–‰ë ¬ ê³„ì‚° =====
    rx = np.array([[1, 0, 0], 
                   [0, np.cos(angle_x), -np.sin(angle_x)], 
                   [0, np.sin(angle_x), np.cos(angle_x)]])
    ry = np.array([[np.cos(angle_y), 0, np.sin(angle_y)], 
                   [0, 1, 0], 
                   [-np.sin(angle_y), 0, np.cos(angle_y)]])
    
    # ===== 3D íˆ¬ì˜ ë° íë¸Œ ê·¸ë¦¬ê¸° =====
    projected_points = []
    for p in points:
        rotated = ry @ (rx @ p)
        
        # âœ… ì œë¡œ ë‚˜ëˆ—ì…ˆ ë°©ì§€ (zê°’ ë²”ìœ„ ê²€ì¦)
        z_denominator = 4 - rotated[2]
        if z_denominator <= 0.1:  # ë„ˆë¬´ ê°€ê¹Œìš°ë©´ ìŠ¤í‚µ
            z = 1
        else:
            z = 1 / z_denominator
        
        px = int(rotated[0] * z * 600 + w/2)
        py = int(rotated[1] * z * 600 + h/2)
        
        # ğŸ“ í™”ë©´ ë²”ìœ„ ê²€ì¦ (í™”ë©´ ë°– ì¢Œí‘œ ì²˜ë¦¬)
        px = np.clip(px, 0, w - 1)
        py = np.clip(py, 0, h - 1)
        projected_points.append((px, py))

    # íë¸Œ ì—£ì§€ ê·¸ë¦¬ê¸°
    for edge in edges:
        p1 = projected_points[edge[0]]
        p2 = projected_points[edge[1]]
        # ë²”ìœ„ ê²€ì¦ëœ ì¢Œí‘œë¡œë§Œ ê·¸ë¦¬ê¸°
        if 0 <= p1[0] < w and 0 <= p1[1] < h and 0 <= p2[0] < w and 0 <= p2[1] < h:
            cv2.line(image, p1, p2, (0, 255, 255), 2)

    # ğŸ“º í™”ë©´ í‘œì‹œ
    cv2.putText(image, f"Pinch to control | Press 'q' to quit", (10, 30), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    cv2.imshow('Face Blur + 3D Cube Control', image)
    
    if cv2.waitKey(1) & 0xFF == ord('q'): 
        break

print("âœ… í”„ë¡œê·¸ë¨ ì¢…ë£Œë¨")
cap.release()
cv2.destroyAllWindows()